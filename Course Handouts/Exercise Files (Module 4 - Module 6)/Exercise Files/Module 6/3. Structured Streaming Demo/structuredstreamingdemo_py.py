# -*- coding: utf-8 -*-
"""StructuredStreamingDemo.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IpIs6yzcCJehKXXGFw4QGzaYcohvgrVO
"""

import os
import sys

!pip install pyspark

from pyspark.sql import SparkSession
from pyspark.sql.functions import explode
from pyspark.sql.functions import split

spark=SparkSession.builder.appName("StructuredNetworkWordCount").getOrCreate()

# create df representing the stream of input lines from connection to localhost:9990
lines=spark.readStream.format("socket").option("host","localhost").option("port",9990).load()

#split the lines into words
words=lines.select(explode(split(lines.value," ")).alias("word"))

#generate running word count
wordCounts=words.groupBy("word").count()

#start running the query that prints the running count to the console
query=wordCounts.writeStream.outputMode("complete").format("console").start()

query.awaitTermination()



















